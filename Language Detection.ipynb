{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = ['Arabic', 'French', 'English', 'Spanish', 'Portuguese', 'German', 'Dutch', 'Italian', \n",
    "        'Japanese', 'Hindi', 'Swedish',  'Russian', 'Korean', 'Thai', 'Turkish',\n",
    "        'South Azerbaijani', 'Bulgarian',  'Persian', 'Modern Greek', 'Finnish', 'Armenian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = 'labels.csv'\n",
    "X_1_text = 'x_train.txt'\n",
    "y_1_text = 'y_train.txt'\n",
    "X_2_text = 'x_test.txt'\n",
    "y_2_text = 'y_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>English</th>\n",
       "      <th>Wiki Code</th>\n",
       "      <th>ISO 369-3</th>\n",
       "      <th>German</th>\n",
       "      <th>Language family</th>\n",
       "      <th>Writing system</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace</td>\n",
       "      <td>Achinese</td>\n",
       "      <td>ace</td>\n",
       "      <td>ace</td>\n",
       "      <td>Achinesisch</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afr</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>af</td>\n",
       "      <td>afr</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>als</td>\n",
       "      <td>Alemannic German</td>\n",
       "      <td>als</td>\n",
       "      <td>gsw</td>\n",
       "      <td>Alemannisch</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ursprünglich nur Elsässisch)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amh</td>\n",
       "      <td>Amharic</td>\n",
       "      <td>am</td>\n",
       "      <td>amh</td>\n",
       "      <td>Amharisch</td>\n",
       "      <td>Afro-Asiatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ang</td>\n",
       "      <td>Old English</td>\n",
       "      <td>ang</td>\n",
       "      <td>ang</td>\n",
       "      <td>Altenglisch</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(ca. 450-1100)</td>\n",
       "      <td>Angelsächsisch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label           English Wiki Code ISO 369-3       German Language family  \\\n",
       "0   ace          Achinese       ace       ace  Achinesisch    Austronesian   \n",
       "1   afr         Afrikaans        af       afr    Afrikaans   Indo-European   \n",
       "2   als  Alemannic German       als       gsw  Alemannisch   Indo-European   \n",
       "3   amh           Amharic        am       amh    Amharisch    Afro-Asiatic   \n",
       "4   ang      Old English        ang       ang  Altenglisch   Indo-European   \n",
       "\n",
       "  Writing system                        Remarks        Synonyms  \n",
       "0            NaN                            NaN             NaN  \n",
       "1            NaN                            NaN             NaN  \n",
       "2            NaN  (ursprünglich nur Elsässisch)             NaN  \n",
       "3            NaN                            NaN             NaN  \n",
       "4            NaN                 (ca. 450-1100)  Angelsächsisch  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_df = pd.read_csv(lb, sep=';')\n",
    "lb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ara',\n",
       " 'azb',\n",
       " 'bul',\n",
       " 'deu',\n",
       " 'ell',\n",
       " 'eng',\n",
       " 'fas',\n",
       " 'fin',\n",
       " 'fra',\n",
       " 'hin',\n",
       " 'hye',\n",
       " 'ita',\n",
       " 'jpn',\n",
       " 'kor',\n",
       " 'nld',\n",
       " 'por',\n",
       " 'rus',\n",
       " 'spa',\n",
       " 'swe',\n",
       " 'tha',\n",
       " 'tur']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(lb_df[lb_df['English'].isin(lang)]['Label'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arabic',\n",
       " 'South Azerbaijani',\n",
       " 'Bulgarian',\n",
       " 'German',\n",
       " 'Modern Greek',\n",
       " 'English',\n",
       " 'Persian',\n",
       " 'Finnish',\n",
       " 'French',\n",
       " 'Hindi',\n",
       " 'Armenian',\n",
       " 'Italian',\n",
       " 'Japanese',\n",
       " 'Korean',\n",
       " 'Dutch',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Spanish',\n",
       " 'Swedish',\n",
       " 'Thai',\n",
       " 'Turkish']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_names = (list(lb_df[lb_df['English'].isin(lang)]['English']))\n",
    "labels_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(X_text, y_text):\n",
    "    y_df = pd.read_csv(y_text, header=None)\n",
    "    y_df.columns = ['Label']\n",
    "    with open(X_text, encoding='utf8') as file :\n",
    "        X_pars = file.readlines()\n",
    "    X_pars = [t.strip() for t in X_pars]\n",
    "    X_df = pd.DataFrame(X_pars, columns=['Paragraph'])\n",
    "    X_df = X_df[y_df['Label'].isin(labels)]\n",
    "    y_df = y_df[y_df['Label'].isin(labels)]\n",
    "    return (X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1 = read_text(X_1_text, y_1_text)\n",
    "X_2, y_2 = read_text(X_2_text, y_2_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sebes, Joseph; Pereira Thomas (1961) (på eng)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>De spons behoort tot het geslacht Haliclona en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Tsutinalar (İngilizce: Tsuut'ina): Kanada'da A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Paragraph\n",
       "1   Sebes, Joseph; Pereira Thomas (1961) (på eng)....\n",
       "4   ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...\n",
       "26  De spons behoort tot het geslacht Haliclona en...\n",
       "29  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...\n",
       "38  Tsutinalar (İngilizce: Tsuut'ina): Kanada'da A..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= pd.concat([X_1, X_2])\n",
    "y= pd.concat([y_1, y_2])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>swe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jpn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label\n",
       "1    swe\n",
       "4    tha\n",
       "26   nld\n",
       "29   jpn\n",
       "38   tur"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "swe    1000\n",
       "fas    1000\n",
       "tha    1000\n",
       "jpn    1000\n",
       "ara    1000\n",
       "spa    1000\n",
       "kor    1000\n",
       "ita    1000\n",
       "azb    1000\n",
       "rus    1000\n",
       "nld    1000\n",
       "deu    1000\n",
       "ell    1000\n",
       "fin    1000\n",
       "eng    1000\n",
       "tur    1000\n",
       "por    1000\n",
       "hye    1000\n",
       "fra    1000\n",
       "bul    1000\n",
       "hin    1000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         sebes joseph pereira thomas  på eng the jesuit...\n",
       "4         ถนนเจรญกรง อกษรโรมน thanon charoen krung เรมตง...\n",
       "26        de spons behoort tot het geslacht haliclona en...\n",
       "29        エノが行きがかりでバスに乗ってしまい気分が悪くなった際に助けるが今すぐバスを降りたいと運転手...\n",
       "38        tsutinalar ingilizce tsuutina kanadada alberta...\n",
       "                                ...                        \n",
       "117446    ο οτορίνο ρεσπίγκι ottorino respighi μπολόνια ...\n",
       "117450    hors du terrain les années  et  sont des année...\n",
       "117463    ใน พศ  หลกจากทเสดจประพาสแหลมมลาย ชวา อนเดยทรงไ...\n",
       "117464    con motivo de la celebración del septuagésimoq...\n",
       "117472    چاپ و شدت قالخانا قدر و دین تماما یالنیز اللها...\n",
       "Name: Paragraph, Length: 21000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Paragraph'] = X['Paragraph'].str.lower() #lower case\n",
    "X['Paragraph'] = X['Paragraph'].str.replace('[^\\w\\s]','') #Remove Punctuation\n",
    "X['Paragraph'] = X['Paragraph'].str.replace('\\d+','') #Remove numbers\n",
    "X['Paragraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "text = X.Paragraph\n",
    "language = y.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, language, test_size=0.30, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14700,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14700, 217095)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello everybody it is me' => eng\n",
      "'Le ciel est beau' => fra\n"
     ]
    }
   ],
   "source": [
    "doc = ['Hello everybody it is me', 'Le ciel est beau']\n",
    "X_doc_counts = count_vect.transform(doc)\n",
    "X_doc_tfidf = tfidf_transformer.transform(X_doc_counts)\n",
    "\n",
    "predicted = clf.predict(X_doc_tfidf)\n",
    "\n",
    "for doc, language in zip(doc, predicted):\n",
    "    print ('%r => %s' % (doc, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_NB = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()), ])\n",
    "lang_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252380952380952"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lang_NB.predict(X_test)\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SVC())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_svm = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SVC()), ])\n",
    "lang_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "lang_svm = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)), ])\n",
    "lang_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634920634920635"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1 = lang_svm.predict(X_test)\n",
    "accuracy_score(y_test,predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "           Arabic       0.99      0.99      0.99       323\n",
      "           French       1.00      0.99      1.00       294\n",
      "          English       0.89      0.96      0.92       295\n",
      "          Spanish       0.94      0.98      0.96       290\n",
      "       Portuguese       1.00      0.99      1.00       312\n",
      "           German       0.78      0.99      0.87       277\n",
      "            Dutch       1.00      1.00      1.00       294\n",
      "          Italian       1.00      0.99      1.00       323\n",
      "         Japanese       0.96      1.00      0.98       301\n",
      "            Hindi       1.00      0.98      0.99       305\n",
      "          Swedish       1.00      0.95      0.97       286\n",
      "          Russian       0.98      0.98      0.98       309\n",
      "           Korean       0.84      0.91      0.87       305\n",
      "             Thai       1.00      0.99      0.99       311\n",
      "          Turkish       0.98      0.97      0.98       262\n",
      "South Azerbaijani       0.98      0.94      0.96       313\n",
      "        Bulgarian       0.99      0.89      0.93       305\n",
      "          Persian       0.99      0.98      0.98       300\n",
      "     Modern Greek       0.99      1.00      0.99       295\n",
      "          Finnish       0.99      0.78      0.87       311\n",
      "         Armenian       1.00      0.99      0.99       289\n",
      "\n",
      "         accuracy                           0.96      6300\n",
      "        macro avg       0.97      0.96      0.96      6300\n",
      "     weighted avg       0.97      0.96      0.96      6300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predictions_1,\n",
    "    target_names=lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[321,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 292,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 282,   5,   0,   6,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 284,   0,   2,   0,   0,   3,   0,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   2, 309,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 273,   0,   0,   1,   0,   0,   0,   1,\n",
       "          0,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0, 293,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0, 321,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 301,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   7,   0,   0,   0, 298,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   2,   0,   5,   0,   0,   1,   0, 272,   1,   0,\n",
       "          0,   1,   0,   3,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   4,   0,   0,   0,   0,   0, 303,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   1,   4,   0,   7,   0,   0,   2,   0,   0,   0, 279,\n",
       "          0,   1,   2,   1,   2,   2,   3,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   2,\n",
       "        307,   0,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   3,   0,   0,   0,   2,\n",
       "          0, 255,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   2,   0,  17,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 294,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  32,   0,   0,   2,   0,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0,   0, 270,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   4,   0,   0,   1,   0,   0,   1,   0,\n",
       "          0,   0,   0,   0, 293,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 294,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  14,   0,   0,   0,   0,   0,   1,  50,\n",
       "          0,   0,   2,   0,   0,   0, 244,   0],\n",
       "       [  0,   0,   0,   1,   0,   3,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 285]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_lang_svm = GridSearchCV(lang_svm, parameters, cv=5, n_jobs=-1)\n",
    "gs_lang_svm = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671428571428571"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param, gs_lang_svm.best_params_[param]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello everybody it is me' => eng\n",
      "'Le ciel est beau' => fra\n",
      "'hello je suis man morocco' => tha\n"
     ]
    }
   ],
   "source": [
    "doc = ['Hello everybody it is me', 'Le ciel est beau', 'hello je suis man morocco']\n",
    "\n",
    "\n",
    "predicted = gs_lang_svm.predict(doc)\n",
    "\n",
    "for doc, language in zip(doc, predicted):\n",
    "    print ('%r => %s' % (doc, language))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
